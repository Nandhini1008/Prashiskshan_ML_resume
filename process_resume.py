"""
Resume Processing Pipeline - Complete Backend Flow

This file handles the complete resume processing flow:
1. Accept PDF file upload
2. Extract text using OCR pipeline
3. Analyze resume using ATS evaluator
4. Return JSON results

NO UI - Pure backend processing function.
"""

import sys
import os
import json
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# Load environment variables from .env file (local) or /etc/secrets/.env (Render)
load_dotenv()  # Try local .env first
load_dotenv('/etc/secrets/.env')  # Then try Render secret files location

# Debug: Print API key status when process_resume is imported
print("="*60)
print("ğŸ”§ Process Resume Environment Check")
print("="*60)
print(f"GOOGLE_API_KEY present: {bool(os.getenv('GOOGLE_API_KEY'))}")
print(f"AI_GEMINI_API_KEY present: {bool(os.getenv('AI_GEMINI_API_KEY'))}")
print(f"RUBRIC_GEMINI_API_KEY present: {bool(os.getenv('RUBRIC_GEMINI_API_KEY'))}")
print("="*60)

# Add OCR directory to path (COMMENTED OUT - Using PyPDF2 only for Render deployment)
# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'OCR'))

# OCR imports (COMMENTED OUT - Using PyPDF2 only)
# from OCR.ocr_pdf_pipeline import PDFTextExtractor

# Direct PDF extraction
import PyPDF2

from resume_evaluator import ResumeEvaluator
from resume_enhancer import ResumeEnhancer

# PDF Generator (optional - requires reportlab which is heavy for Render free tier)
try:
    from resume_pdf_generator import ResumePDFGenerator
    PDF_GENERATION_AVAILABLE = True
except ImportError:
    PDF_GENERATION_AVAILABLE = False
    print("Warning: PDF generation disabled (reportlab not installed)")


class ResumeProcessor:
    """Complete resume processing pipeline."""
    
    def __init__(self):
        """Initialize resume evaluator and enhancer (OCR disabled for Render deployment)."""
        # OCR extractor (COMMENTED OUT - Using PyPDF2 only)
        # self.ocr_extractor = PDFTextExtractor()
        
        self.resume_evaluator = ResumeEvaluator()
        self.enhancer = ResumeEnhancer()
        
        # PDF generator (optional)
        if PDF_GENERATION_AVAILABLE:
            self.pdf_generator = ResumePDFGenerator()
        else:
            self.pdf_generator = None
    
    def process_resume_pdf(
        self, 
        pdf_path: str, 
        use_ocr: bool = False,
        enhance: bool = True
    ) -> Dict[str, Any]:
        """
        Complete pipeline: PDF â†’ OCR â†’ Analysis â†’ Enhancement â†’ PDF
        
        Args:
            pdf_path: Path to the PDF resume file
            use_ocr: If True, use OCR for image-based PDFs. 
                     If False, try direct text extraction first.
            enhance: If True, automatically generate enhanced resume PDF
        
        Returns:
            Dictionary with extraction info, evaluation results, and enhancement info
        """
        try:
            # Step 1: Extract text from PDF
            print(f"ğŸ“„ Processing: {pdf_path}")
            print(f"ğŸ” Extraction method: {'OCR' if use_ocr else 'Direct text extraction'}")
            
            resume_text = self._extract_text_from_pdf(pdf_path, use_ocr)
            
            if not resume_text or len(resume_text.strip()) < 50:
                return {
                    'success': False,
                    'error': 'Failed to extract sufficient text from PDF',
                    'resume_text': resume_text,
                    'evaluation': None,
                    'enhancement': None
                }
            
            print(f"âœ“ Extracted {len(resume_text)} characters")
            
            # Step 2: Evaluate resume
            print("ğŸ” Analyzing resume...")
            evaluation = self.resume_evaluator.evaluate(resume_text)
            
            print(f"âœ“ Analysis complete - Final Score: {evaluation['final_ats_score']}/100")
            
            # Step 3: Enhance resume (if requested)
            enhancement_result = None
            if enhance:
                print("âœ¨ Enhancing resume...")
                enhancement_result = self._enhance_resume(
                    pdf_path, 
                    resume_text, 
                    evaluation,
                    save_files=False  # Don't save files, return data directly
                )
                
                if enhancement_result.get('success'):
                    enhancements_count = enhancement_result.get('enhancements_count', 0)
                    print(f"âœ“ Generated {enhancements_count} enhancements")
                    print(f"   Enhancement JSON data included in response")
                else:
                    print(f"âš  Enhancement failed: {enhancement_result.get('error')}")
            
            # Step 4: Return combined results
            return {
                'success': True,
                'resume_text': resume_text,
                'text_length': len(resume_text),
                'evaluation': evaluation,
                'enhancement': enhancement_result
            }
            
        except FileNotFoundError:
            return {
                'success': False,
                'error': f'PDF file not found: {pdf_path}',
                'resume_text': None,
                'evaluation': None,
                'enhancement': None
            }
        except Exception as e:
            return {
                'success': False,
                'error': f'Processing failed: {str(e)}',
                'resume_text': None,
                'evaluation': None,
                'enhancement': None
            }
    
    def _extract_text_from_pdf(self, pdf_path: str, use_ocr: bool) -> str:
        """
        Extract text from PDF using PyPDF2 (OCR disabled for Render deployment).
        
        Args:
            pdf_path: Path to PDF file
            use_ocr: Ignored - always uses PyPDF2 direct extraction
            
        Returns:
            Extracted plain text
        """
        # Use PyPDF2 for direct text extraction (works for 95% of resumes)
        try:
            print("ğŸ” Using PyPDF2 direct text extraction...")
            text_parts = []
            
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                total_pages = len(pdf_reader.pages)
                
                print(f"   ğŸ“„ Processing {total_pages} pages...")
                
                for page_num in range(total_pages):
                    page = pdf_reader.pages[page_num]
                    page_text = page.extract_text()
                    
                    if page_text and page_text.strip():
                        text_parts.append(page_text)
                
                if not text_parts:
                    raise Exception("No text could be extracted from PDF")
                
                extracted_text = '\n'.join(text_parts)
                print(f"   âœ… Extracted {len(extracted_text)} characters from {total_pages} pages")
                
                return extracted_text
                
        except Exception as e:
            print(f"âŒ PyPDF2 extraction failed: {e}")
            raise Exception(f"Failed to extract text from PDF: {str(e)}")
        
        # OCR extraction (COMMENTED OUT - Not available in Render deployment)
        # This would require heavy dependencies (torch, paddleocr, opencv)
        # For OCR support, deploy to Hugging Face Spaces or upgrade Render plan
        #
        # if not use_ocr:
        #     try:
        #         result = self.ocr_extractor.extract_text_from_pdf(pdf_path, use_ocr=False)
        #         ...
        #     except Exception as e:
        #         print(f"âš  Direct extraction failed: {e}")
        #
        # print("ğŸ” Using OCR extraction...")
        # result = self.ocr_extractor.extract_text_from_pdf(pdf_path, use_ocr=True)
        # ...
    
    def _enhance_resume(
        self,
        pdf_path: str,
        resume_text: str,
        evaluation: Dict[str, Any],
        save_files: bool = False
    ) -> Dict[str, Any]:
        """
        Enhance resume based on evaluation results.
        
        Args:
            pdf_path: Path to original PDF
            resume_text: Extracted resume text
            evaluation: Evaluation results
            save_files: If True, save files to disk. If False, return data only.
            
        Returns:
            Dictionary with enhancement results including full JSON data
        """
        try:
            # Import simple enhancer
            from simple_enhancer import SimpleResumeEnhancer
            
            # Extract candidate name from resume text
            candidate_name = self._extract_candidate_name(resume_text)
            
            # Use simple text-based enhancement
            enhancer = SimpleResumeEnhancer()
            result = enhancer.enhance_resume_text(
                pdf_path, 
                resume_text, 
                evaluation,
                save_files=save_files
            )
            
            if not result.get('success'):
                return result
            
            # Track improvements
            improvements_applied = [
                "Enhanced resume content with LLM while preserving structure",
                "Improved wording for clarity and professionalism",
                "Strengthened action verbs and technical language",
                "Added impact context without inventing metrics",
                "Maintained all dates, roles, and original information"
            ]
            
            # Build response with full enhancement JSON data
            response = {
                'success': True,
                'enhancement': result.get('enhancement'),  # Full enhancement JSON
                'enhanced_text': result.get('enhanced_text'),  # Enhanced text content
                'enhancements_count': result.get('enhancements_count', 0),
                'improvements_applied': improvements_applied,
                'candidate_name': candidate_name,
                'message': result.get('message', 'Enhancements generated successfully!')
            }
            
            # Include file paths only if files were saved
            if save_files:
                response.update({
                    'enhancement_json_path': result.get('enhancement_json_path'),
                    'enhanced_text_path': result.get('enhanced_text_path'),
                    'original_text_path': result.get('original_text_path'),
                    'comparison_path': result.get('comparison_path'),
                    'enhanced_pdf_path': result.get('enhanced_pdf_path'),
                })
            
            return response
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'enhanced_text_path': None,
                'improvements_applied': []
            }
    
    def _extract_candidate_name(self, resume_text: str) -> str:
        """Extract candidate name from resume text."""
        import re
        
        lines = resume_text.split('\n')
        
        # First, try to find a line that looks like a name (2-4 capitalized words)
        name_pattern = r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+){1,3})\b'
        
        # Search in first 50 lines for name
        for line in lines[:50]:
            line = line.strip()
            
            # Skip empty lines or lines that are too long
            if not line or len(line) > 60:
                continue
            
            # Skip lines with technical keywords
            if any(keyword in line.lower() for keyword in [
                'java', 'python', 'experience', 'developer', 'engineer',
                'at least', 'years', 'working', 'knowledge', 'skills',
                'ai,', 'llm', 'rag', 'oop', 'spring', 'html', 'css',
                'angularjs', 'react', 'javascript', 'software', 'deep',
                'practices', 'modules', 'based on', 'degree in', 'university',
                'college', 'master', 'bachelor', 'certified', 'certification'
            ]):
                continue
            
            # Look for name pattern
            match = re.search(name_pattern, line)
            if match:
                potential_name = match.group(1)
                
                # Verify it's not a company or location
                if not any(word in potential_name for word in ['Microsoft', 'Visa', 'Seattle', 'Austin', 'India', 'USA']):
                    # Clean name for filename
                    name = potential_name.replace(' ', '_').replace(',', '')
                    # Remove special characters
                    name = ''.join(c for c in name if c.isalnum() or c == '_')
                    if name and len(name) > 3:
                        return name
        
        # Fallback: Look for all-caps name (like "MADHAV SOMANI")
        for line in lines:
            line = line.strip()
            # Check for all-caps name pattern
            if re.match(r'^[A-Z\s]{5,40}$', line):
                # Check if it's not a section header
                if not any(keyword in line for keyword in [
                    'EXPERIENCE', 'EDUCATION', 'SKILLS', 'PROJECTS', 
                    'ACCOMPLISHMENTS', 'CERTIFICATIONS', 'SUMMARY', 'CONTACT'
                ]):
                    name = line.replace(' ', '_')
                    name = ''.join(c for c in name if c.isalnum() or c == '_')
                    if name and len(name) > 3:
                        return name
        
        return "Candidate"
    
    def _track_improvements(
        self,
        evaluation: Dict[str, Any],
        enhanced_content: Dict[str, Any]
    ) -> list[str]:
        """Track what improvements were applied."""
        improvements = []
        
        # Check for bullet point enhancements
        exp_count = len(enhanced_content.get('experience', []))
        if exp_count > 0:
            total_bullets = sum(
                len(exp.get('bullets', [])) 
                for exp in enhanced_content.get('experience', [])
            )
            improvements.append(f"Enhanced {total_bullets} experience bullet points with metrics and impact")
        
        # Check for skills filtering
        skills_count = len(enhanced_content.get('skills', []))
        if skills_count > 0:
            improvements.append(f"Filtered and organized {skills_count} proven technical skills")
        
        # Check for projects enhancement
        projects_count = len(enhanced_content.get('projects', []))
        if projects_count > 0:
            improvements.append(f"Enhanced {projects_count} projects with impact and outcomes")
        
        # Check for generic content removal
        eval_improvements = evaluation.get('resume_improvements', {})
        if eval_improvements.get('keyword_and_skills'):
            for issue in eval_improvements['keyword_and_skills']:
                if 'generic text block' in issue.get('issue', '').lower():
                    improvements.append("Removed generic copy-pasted text block")
                    break
        
        # Check for formatting improvements
        if eval_improvements.get('structure_and_formatting'):
            improvements.append("Applied professional formatting and structure")
        
        # General improvements
        improvements.append("Improved action verbs and professional language")
        improvements.append("Enhanced ATS compatibility")
        
        return improvements


def process_resume_file(pdf_path: str, use_ocr: bool = False) -> Dict[str, Any]:
    """
    Convenience function to process a resume PDF file.
    
    Args:
        pdf_path: Path to the PDF resume file
        use_ocr: If True, use OCR. If False, try direct extraction first.
    
    Returns:
        Dictionary with processing results and evaluation
    
    Example:
        >>> result = process_resume_file('resume.pdf')
        >>> print(f"Score: {result['evaluation']['final_ats_score']}/100")
    """
    processor = ResumeProcessor()
    return processor.process_resume_pdf(pdf_path, use_ocr)


def main():
    """
    Example usage and testing.
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='Process and analyze resume PDF')
    parser.add_argument('pdf_file', help='Path to resume PDF file')
    parser.add_argument('--ocr', action='store_true', 
                       help='Force OCR extraction (for image-based PDFs)')
    parser.add_argument('--output', '-o', help='Output JSON file path')
    
    args = parser.parse_args()
    
    print("\n" + "="*60)
    print("ğŸš€ RESUME PROCESSING PIPELINE")
    print("="*60 + "\n")
    
    # Process the resume
    result = process_resume_file(args.pdf_file, use_ocr=args.ocr)
    
    if result['success']:
        evaluation = result['evaluation']
        
        print("\n" + "="*60)
        print("ğŸ“Š EVALUATION RESULTS")
        print("="*60 + "\n")
        
        print(f"Standard ATS Score:  {evaluation['standard_ats_score']}/100")
        print(f"AI ATS Score:        {evaluation['ai_ats_score']}/100")
        print(f"Final ATS Score:     {evaluation['final_ats_score']}/100")
        
        print("\nâœ… STRENGTHS:")
        for i, strength in enumerate(evaluation['analysis_summary']['strengths'][:5], 1):
            print(f"   {i}. {strength}")
        
        print("\nâš ï¸  WEAKNESSES:")
        for i, weakness in enumerate(evaluation['analysis_summary']['weaknesses'][:5], 1):
            print(f"   {i}. {weakness}")
        
        print("\nğŸ’¡ TOP IMPROVEMENTS:")
        improvements = evaluation['resume_improvements']
        
        # Show top 2 from each category
        for category, items in improvements.items():
            if items:
                print(f"\n   ğŸ“Œ {category.replace('_', ' ').title()}:")
                for imp in items[:2]:
                    print(f"      â€¢ {imp['recommended_fix']}")
        
        # Save to file if requested (for CLI usage only)
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ’¾ Full results saved to: {args.output}")
        # Note: When used as API backend, results are returned directly without saving files
        
        
        # Display enhancement results
        if result.get('enhancement') and result['enhancement'].get('success'):
            enhancement = result['enhancement']
            print("\n" + "="*60)
            print("âœ¨ RESUME ENHANCEMENT COMPLETED")
            print("="*60 + "\n")
            
            # Show enhancement JSON first (most important for frontend)
            if enhancement.get('enhancement_json_path'):
                print(f"ğŸ¯ Enhancement JSON: {enhancement.get('enhancement_json_path', 'N/A')}")
                print(f"   ğŸ“Š {enhancement.get('enhancements_count', 0)} enhancements generated")
                print()
            
            print(f"ğŸ“„ Original Text: {enhancement.get('original_text_path', 'N/A')}")
            print(f"ğŸ“ Enhanced Text: {enhancement.get('enhanced_text_path', 'N/A')}")
            print(f"ğŸ“Š Comparison File: {enhancement.get('comparison_path', 'N/A')}")
            
            if enhancement.get('enhanced_pdf_path'):
                print(f"âœ¨ Enhanced PDF: {enhancement.get('enhanced_pdf_path', 'N/A')}")
            
            print(f"\nğŸ’¡ {enhancement.get('message', '')}")
            print(f"\nğŸ¯ Improvements Applied ({len(enhancement.get('improvements_applied', []))}):")
            for i, improvement in enumerate(enhancement.get('improvements_applied', []), 1):
                print(f"   {i}. {improvement}")
            
            if enhancement.get('enhanced_pdf_path'):
                print(f"\nğŸ“ Your enhanced PDF is ready!")
                print(f"   ğŸ“„ {os.path.basename(enhancement.get('enhanced_pdf_path', ''))}")
                print(f"   âœ… Pixel-perfect layout preservation")
                print(f"   âœ… Enhanced content with improved wording")
            
            if enhancement.get('enhancement_json_path'):
                print(f"\nğŸ”§ For Frontend Integration:")
                print(f"   ğŸ“ Use: {os.path.basename(enhancement.get('enhancement_json_path', ''))}")
                print(f"   âœ… {enhancement.get('enhancements_count', 0)} enhancements ready to apply")
        
    else:
        print("\nâŒ PROCESSING FAILED")
        print(f"Error: {result['error']}")
    
    print("\n" + "="*60 + "\n")


if __name__ == "__main__":
    # If run directly, use command-line interface
    main()
